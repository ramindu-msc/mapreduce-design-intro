{
  "paragraphs": [
    {
      "text": "%md\n# Creating DataFrames",
      "user": "anonymous",
      "dateUpdated": "2020-12-13T09:47:20+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1607852840444_791227000",
      "id": "20161121-211804_261745742",
      "dateCreated": "2020-12-13T09:47:20+0000",
      "status": "READY",
      "focus": true,
      "$$hashKey": "object:3766"
    },
    {
      "text": "%pyspark\n\n# spark is an existing SparkSession\ndf = spark.read.json(\"/data/people.json\")\n# Displays the content of the DataFrame to stdout\ndf.show()\n# +----+-------+\n# | age|   name|\n# +----+-------+\n# |null|Michael|\n# |  30|   Andy|\n# |  19| Justin|\n# +----+-------+",
      "user": "anonymous",
      "dateUpdated": "2020-12-13T09:47:20+0000",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 9,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true
      },
      "settings": {
        "params": {
          "name": "",
          "spark_home": "/Users/suho/Documents/msc/iit/big-data-programming/sessions/week9/lab/spark-2.0.1-bin-hadoop2.7"
        },
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1607852840445_1809479955",
      "id": "20161121-211505_204906499",
      "dateCreated": "2020-12-13T09:47:20+0000",
      "status": "READY",
      "$$hashKey": "object:3767"
    },
    {
      "text": "%md\n# Untyped Dataset Operations (aka DataFrame Operations)",
      "user": "anonymous",
      "dateUpdated": "2020-12-13T09:47:20+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1607852840446_161367497",
      "id": "20161121-212243_1042559294",
      "dateCreated": "2020-12-13T09:47:20+0000",
      "status": "READY",
      "$$hashKey": "object:3768"
    },
    {
      "text": "%pyspark\n\n# spark, df are from the previous example\n# Print the schema in a tree format\ndf.printSchema()\n# root\n# |-- age: long (nullable = true)\n# |-- name: string (nullable = true)\n\n# Select only the \"name\" column\ndf.select(\"name\").show()\n# +-------+\n# |   name|\n# +-------+\n# |Michael|\n# |   Andy|\n# | Justin|\n# +-------+\n\n# Select everybody, but increment the age by 1\ndf.select(df['name'], df['age'] + 1).show()\n# +-------+---------+\n# |   name|(age + 1)|\n# +-------+---------+\n# |Michael|     null|\n# |   Andy|       31|\n# | Justin|       20|\n# +-------+---------+\n\n# Select people older than 21\ndf.filter(df['age'] > 21).show()\n# +---+----+\n# |age|name|\n# +---+----+\n# | 30|Andy|\n# +---+----+\n\n# Count people by age\ndf.groupBy(\"age\").count().show()\n# +----+-----+\n# | age|count|\n# +----+-----+\n# |  19|    1|\n# |null|    1|\n# |  30|    1|\n# +----+-----+",
      "user": "anonymous",
      "dateUpdated": "2020-12-13T09:47:20+0000",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 9,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1607852840446_1995274670",
      "id": "20161121-212329_269221065",
      "dateCreated": "2020-12-13T09:47:20+0000",
      "status": "READY",
      "$$hashKey": "object:3769"
    },
    {
      "text": "%md\n# Running SQL Queries Programmatically",
      "user": "anonymous",
      "dateUpdated": "2020-12-13T09:47:20+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1607852840446_-1406394432",
      "id": "20161121-212510_1424611231",
      "dateCreated": "2020-12-13T09:47:20+0000",
      "status": "READY",
      "$$hashKey": "object:3770"
    },
    {
      "text": "%pyspark\n\n# Register the DataFrame as a SQL temporary view\ndf.createOrReplaceTempView(\"people\")\n\nsqlDF = spark.sql(\"SELECT * FROM people\")\nsqlDF.show()\n# +----+-------+\n# | age|   name|\n# +----+-------+\n# |null|Michael|\n# |  30|   Andy|\n# |  19| Justin|\n# +----+-------+",
      "user": "anonymous",
      "dateUpdated": "2020-12-13T09:47:20+0000",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 9,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1607852840447_-2089782851",
      "id": "20161121-212653_1761768042",
      "dateCreated": "2020-12-13T09:47:20+0000",
      "status": "READY",
      "$$hashKey": "object:3771"
    },
    {
      "text": "%sql\nSELECT * FROM people",
      "user": "anonymous",
      "dateUpdated": "2020-12-13T09:47:20+0000",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/sql",
        "fontSize": 9,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "age": "string",
                      "name": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                },
                "multiBarChart": {
                  "rotate": {
                    "degree": "-45"
                  },
                  "xLabelStatus": "default"
                }
              },
              "commonSetting": {},
              "keys": [
                {
                  "name": "age",
                  "index": 0,
                  "aggr": "sum"
                }
              ],
              "groups": [],
              "values": [
                {
                  "name": "name",
                  "index": 1,
                  "aggr": "sum"
                }
              ]
            },
            "helium": {}
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1607852840447_1637929135",
      "id": "20191125-144738_1887567369",
      "dateCreated": "2020-12-13T09:47:20+0000",
      "status": "READY",
      "$$hashKey": "object:3772"
    },
    {
      "text": "%md\n\n# Creating Datasets",
      "user": "anonymous",
      "dateUpdated": "2020-12-13T09:47:20+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1607852840447_-905180404",
      "id": "20161121-212717_908245571",
      "dateCreated": "2020-12-13T09:47:20+0000",
      "status": "READY",
      "$$hashKey": "object:3773"
    },
    {
      "text": "%spark\n\nimport spark.implicits._\n// Note: Case classes in Scala 2.10 can support only up to 22 fields. To work around this limit,\n// you can use custom classes that implement the Product interface\ncase class Person(name: String, age: Long)\n\n// Encoders are created for case classes\nval caseClassDS = Seq(Person(\"Andy\", 32), Person(\"Andy1\", 33)).toDS()\ncaseClassDS.show()\n// +----+---+\n// |name|age|\n// +----+---+\n// |Andy| 32|\n// +----+---+\n\n// Encoders for most common types are automatically provided by importing spark.implicits._\nval primitiveDS = Seq(1, 2, 3).toDS()\nprimitiveDS.map(_ + 1).collect() // Returns: Array(2, 3, 4)\n\n// DataFrames can be converted to a Dataset by providing a class. Mapping will be done by name\nval path =\"/data/people.json\"\nval peopleDS = spark.read.json(path).as[Person]\npeopleDS.show()\n// +----+-------+\n// | age|   name|\n// +----+-------+\n// |null|Michael|\n// |  30|   Andy|\n// |  19| Justin|\n// +----+-------+",
      "user": "anonymous",
      "dateUpdated": "2020-12-13T09:47:20+0000",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true
      },
      "settings": {
        "params": {
          "spark_home": "/Users/suho/Documents/msc/iit/big-data-programming/sessions/week9/lab/spark-2.0.1-bin-hadoop2.7"
        },
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1607852840447_-34266745",
      "id": "20161121-213642_898338092",
      "dateCreated": "2020-12-13T09:47:20+0000",
      "status": "READY",
      "$$hashKey": "object:3774"
    },
    {
      "text": "%md \n# Inferring the Schema Using Reflection",
      "user": "anonymous",
      "dateUpdated": "2020-12-13T09:47:20+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1607852840447_-831252113",
      "id": "20161121-213745_455199652",
      "dateCreated": "2020-12-13T09:47:20+0000",
      "status": "READY",
      "$$hashKey": "object:3775"
    },
    {
      "text": "%pyspark\n\nfrom pyspark.sql import *\n\n# Load a text file and convert each line to a Row.\nlines = sc.textFile(\"/data/people.txt\")\nprint(lines.collect())\n\nparts = lines.map(lambda l: l.split(\",\"))\npeople = parts.map(lambda p: Row(name=p[0], age=int(p[1])))\n\n\n# Infer the schema, and register the DataFrame as a table.\nschemaPeople = spark.createDataFrame(people)\nschemaPeople.createOrReplaceTempView(\"people\")\n\n# SQL can be run over DataFrames that have been registered as a table.\nteenagers = spark.sql(\"SELECT name FROM people WHERE age >= 13 AND age <= 19\")\n\n# The results of SQL queries are Dataframe objects.\n# rdd returns the content as an :class:`pyspark.RDD` of :class:`Row`.\nteenNames = teenagers.rdd.map(lambda p: \"Name: \" + p.name).collect()\nfor name in teenNames:\n    print(name)\n# Name: Justin",
      "user": "anonymous",
      "dateUpdated": "2020-12-13T09:47:20+0000",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 9,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true
      },
      "settings": {
        "params": {
          "spark_home": "/Users/suho/Documents/msc/iit/big-data-programming/sessions/week9/lab/spark-2.0.1-bin-hadoop2.7"
        },
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1607852840448_-574443398",
      "id": "20161121-214219_563939179",
      "dateCreated": "2020-12-13T09:47:20+0000",
      "status": "READY",
      "$$hashKey": "object:3776"
    },
    {
      "text": "%md\n\n# Programmatically Specifying the Schema",
      "user": "anonymous",
      "dateUpdated": "2020-12-13T09:47:20+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1607852840448_-1112682941",
      "id": "20161121-214254_1160849755",
      "dateCreated": "2020-12-13T09:47:20+0000",
      "status": "READY",
      "$$hashKey": "object:3777"
    },
    {
      "text": "%pyspark\n\n# Import data types\nfrom pyspark.sql.types import *\n\n\n# Load a text file and convert each line to a Row.\nlines = sc.textFile(\"/data/people.txt\")\nparts = lines.map(lambda l: l.split(\",\"))\n# Each line is converted to a tuple.\npeople = parts.map(lambda p: (p[0], p[1].strip()))\n\n# The schema is encoded in a string.\nschemaString = \"name age\"\n\nfields = [StructField(field_name, StringType(), True) for field_name in schemaString.split()]\nschema = StructType(fields)\n\n# Apply the schema to the RDD.\nschemaPeople = spark.createDataFrame(people, schema)\n\n# Creates a temporary view using the DataFrame\nschemaPeople.createOrReplaceTempView(\"people\")\n\n# SQL can be run over DataFrames that have been registered as a table.\nresults = spark.sql(\"SELECT name FROM people\")\n\nresults.show()\n# +-------+\n# |   name|\n# +-------+\n# |Michael|\n# |   Andy|\n# | Justin|\n# +-------+",
      "user": "anonymous",
      "dateUpdated": "2020-12-13T09:47:20+0000",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 9,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true
      },
      "settings": {
        "params": {
          "spark_home": "/Users/suho/Documents/msc/iit/big-data-programming/sessions/week9/lab/spark-2.0.1-bin-hadoop2.7"
        },
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1607852840448_-1931476416",
      "id": "20161121-215434_1308115320",
      "dateCreated": "2020-12-13T09:47:20+0000",
      "status": "READY",
      "$$hashKey": "object:3778"
    },
    {
      "text": "%md\n\n# Data Sources",
      "user": "anonymous",
      "dateUpdated": "2020-12-13T09:47:20+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1607852840448_1442155579",
      "id": "20161121-215556_1513433460",
      "dateCreated": "2020-12-13T09:47:20+0000",
      "status": "READY",
      "$$hashKey": "object:3779"
    },
    {
      "text": "%md \n# Generic Load/Save Functions",
      "user": "anonymous",
      "dateUpdated": "2020-12-13T09:47:20+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1607852840449_-1501840358",
      "id": "20161121-221300_1709976506",
      "dateCreated": "2020-12-13T09:47:20+0000",
      "status": "READY",
      "$$hashKey": "object:3780"
    },
    {
      "text": "%pyspark\n\nimport shutil\nshutil.rmtree('namesAndFavColors.parquet', ignore_errors=True)\n\ndf = spark.read.load(\"/data/users.parquet\")\ndf.show()\ndf.select(\"name\", \"favorite_color\").write.save(\"namesAndFavColors.parquet\")",
      "user": "anonymous",
      "dateUpdated": "2020-12-13T09:47:20+0000",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 9,
        "results": [],
        "enabled": true
      },
      "settings": {
        "params": {
          "spark_home": "/Users/suho/Documents/msc/iit/big-data-programming/sessions/week9/lab/spark-2.0.1-bin-hadoop2.7"
        },
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1607852840449_-171157610",
      "id": "20161121-221324_1792501703",
      "dateCreated": "2020-12-13T09:47:20+0000",
      "status": "READY",
      "$$hashKey": "object:3781"
    },
    {
      "text": "%pyspark\n\ndf = spark.read.load(\"namesAndFavColors.parquet\")\ndf.show()",
      "user": "anonymous",
      "dateUpdated": "2020-12-13T09:47:20+0000",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 9,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1607852840449_1386474342",
      "id": "20161121-221352_253824984",
      "dateCreated": "2020-12-13T09:47:20+0000",
      "status": "READY",
      "$$hashKey": "object:3782"
    },
    {
      "text": "%pyspark\n\nimport shutil\nshutil.rmtree('namesAndAges.parquet', ignore_errors=True)\n\n\ndf = spark.read.load(\"/data/people.json\", format=\"json\")\ndf.select(\"name\", \"age\").write.save(\"namesAndAges.parquet\", format=\"parquet\")\n\ndf = spark.read.load(\"namesAndAges.parquet\")\ndf.show()",
      "user": "anonymous",
      "dateUpdated": "2020-12-13T09:47:20+0000",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 9,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true
      },
      "settings": {
        "params": {
          "spark_home": "/Users/suho/Documents/msc/iit/big-data-programming/sessions/week9/lab/spark-2.0.1-bin-hadoop2.7"
        },
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1607852840449_880576349",
      "id": "20161121-221523_1944730815",
      "dateCreated": "2020-12-13T09:47:20+0000",
      "status": "READY",
      "$$hashKey": "object:3783"
    },
    {
      "text": "%pyspark \n\ndf = spark.sql(\"SELECT * FROM parquet.`namesAndAges.parquet`\")\ndf.show()",
      "user": "anonymous",
      "dateUpdated": "2020-12-13T09:47:20+0000",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 9,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true
      },
      "settings": {
        "params": {
          "spark_home": "/Users/suho/Documents/msc/iit/big-data-programming/sessions/week9/lab/spark-2.0.1-bin-hadoop2.7"
        },
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1607852840450_-115102691",
      "id": "20161121-221645_1477557536",
      "dateCreated": "2020-12-13T09:47:20+0000",
      "status": "READY",
      "$$hashKey": "object:3784"
    },
    {
      "text": "%md\n\n# Loading Data Programmatically",
      "user": "anonymous",
      "dateUpdated": "2020-12-13T09:47:20+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1607852840450_1066837283",
      "id": "20161121-222620_202866957",
      "dateCreated": "2020-12-13T09:47:20+0000",
      "status": "READY",
      "$$hashKey": "object:3785"
    },
    {
      "text": "%pyspark\n\nimport shutil\nshutil.rmtree(\"people.parquet\", ignore_errors=True)\n\npeopleDF = spark.read.json(\"/data/people.json\")\n\n# DataFrames can be saved as Parquet files, maintaining the schema information.\npeopleDF.write.parquet(\"people.parquet\")\n\n# Read in the Parquet file created above.\n# Parquet files are self-describing so the schema is preserved.\n# The result of loading a parquet file is also a DataFrame.\nparquetFile = spark.read.parquet(\"people.parquet\")\n\n# Parquet files can also be used to create a temporary view and then used in SQL statements.\nparquetFile.createOrReplaceTempView(\"parquetFile\")\nteenagers = spark.sql(\"SELECT name FROM parquetFile WHERE age >= 13 AND age <= 19\")\nteenagers.show()\n# +------+\n# |  name|\n# +------+\n# |Justin|\n# +------+",
      "user": "anonymous",
      "dateUpdated": "2020-12-13T09:47:20+0000",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 9,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true
      },
      "settings": {
        "params": {
          "spark_home": "/Users/suho/Documents/msc/iit/big-data-programming/sessions/week9/lab/spark-2.0.1-bin-hadoop2.7"
        },
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1607852840450_391406467",
      "id": "20161121-223150_132443134",
      "dateCreated": "2020-12-13T09:47:20+0000",
      "status": "READY",
      "$$hashKey": "object:3786"
    },
    {
      "text": "%md\n\n# Schema Merging",
      "user": "anonymous",
      "dateUpdated": "2020-12-13T09:47:20+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1607852840451_2121827525",
      "id": "20161121-223224_183585777",
      "dateCreated": "2020-12-13T09:47:20+0000",
      "status": "READY",
      "$$hashKey": "object:3787"
    },
    {
      "text": "%pyspark\n\nimport shutil\nshutil.rmtree('data', ignore_errors=True)\n\n# from pyspark.sql import Row\n\n# spark is from the previous example.\n# Create a simple DataFrame, stored into a partition directory\nsc = spark.sparkContext\n\nsquaresDF = spark.createDataFrame(sc.parallelize(range(1, 6))\n                                  .map(lambda i: Row(single=i, double=i ** 2)))\nsquaresDF.write.parquet(\"data/test_table/key=1\")\n\n# Create another DataFrame in a new partition directory,\n# adding a new column and dropping an existing column\ncubesDF = spark.createDataFrame(sc.parallelize(range(6, 11))\n                                .map(lambda i: Row(single=i, triple=i ** 3)))\ncubesDF.write.parquet(\"data/test_table/key=2\")\n\n# Read the partitioned table\nmergedDF = spark.read.option(\"mergeSchema\", \"true\").parquet(\"data/test_table\")\nmergedDF.printSchema()\n\n# The final schema consists of all 3 columns in the Parquet files together\n# with the partitioning column appeared in the partition directory paths.\n# root\n#  |-- double: long (nullable = true)\n#  |-- single: long (nullable = true)\n#  |-- triple: long (nullable = true)\n#  |-- key: integer (nullable = true)",
      "user": "anonymous",
      "dateUpdated": "2020-12-13T09:47:20+0000",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 9,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1607852840451_-843628819",
      "id": "20161121-223620_204262642",
      "dateCreated": "2020-12-13T09:47:20+0000",
      "status": "READY",
      "$$hashKey": "object:3788"
    },
    {
      "text": "%pyspark\n\nmergedDF = spark.read.option(\"mergeSchema\", \"true\").parquet(\"data/test_table\")\nmergedDF.show()",
      "user": "anonymous",
      "dateUpdated": "2020-12-13T09:47:20+0000",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 9,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1607852840451_-713762269",
      "id": "20161121-223720_479563238",
      "dateCreated": "2020-12-13T09:47:20+0000",
      "status": "READY",
      "$$hashKey": "object:3789"
    },
    {
      "text": "%md\n\n# Spark SQL",
      "user": "anonymous",
      "dateUpdated": "2020-12-13T09:47:20+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1607852840452_-1469830606",
      "id": "20161121-224455_578990309",
      "dateCreated": "2020-12-13T09:47:20+0000",
      "status": "READY",
      "$$hashKey": "object:3790"
    },
    {
      "text": "%sql\nshow tables",
      "user": "anonymous",
      "dateUpdated": "2020-12-13T09:47:20+0000",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/sql",
        "fontSize": 9,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {},
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "database": "string",
                      "tableName": "string",
                      "isTemporary": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            }
          }
        ],
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1607852840452_227419346",
      "id": "20161121-224034_728861532",
      "dateCreated": "2020-12-13T09:47:20+0000",
      "status": "READY",
      "$$hashKey": "object:3791"
    },
    {
      "text": "%sql \n\nselect name, age from people where age > 0",
      "user": "anonymous",
      "dateUpdated": "2020-12-13T09:47:20+0000",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/sql",
        "fontSize": 9,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false,
              "keys": [
                {
                  "name": "name",
                  "index": 0,
                  "aggr": "sum"
                }
              ],
              "values": [
                {
                  "name": "age",
                  "index": 1,
                  "aggr": "sum"
                }
              ],
              "groups": [],
              "scatter": {
                "xAxis": {
                  "name": "name",
                  "index": 0,
                  "aggr": "sum"
                },
                "yAxis": {
                  "name": "age",
                  "index": 1,
                  "aggr": "sum"
                }
              },
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "name": "string",
                      "age": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            },
            "helium": {}
          }
        ],
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1607852840452_-396320935",
      "id": "20161121-224655_1255434563",
      "dateCreated": "2020-12-13T09:47:20+0000",
      "status": "READY",
      "$$hashKey": "object:3792"
    },
    {
      "text": "",
      "user": "anonymous",
      "dateUpdated": "2020-12-13T09:47:20+0000",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "graph": {
          "mode": "table",
          "height": 300,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1607852840452_694545083",
      "id": "20161121-224712_2007083219",
      "dateCreated": "2020-12-13T09:47:20+0000",
      "status": "READY",
      "$$hashKey": "object:3793"
    }
  ],
  "name": "Spark Lab Session",
  "id": "2FS8CVMQ2",
  "defaultInterpreterGroup": "spark",
  "version": "0.9.0-preview1",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false,
    "looknfeel": "default",
    "personalizedMode": "false"
  },
  "info": {},
  "path": "/Spark Lab Session"
}