version: "2"
services:
  namenode:
    image: apache/hadoop:3
    platform: linux/amd64
    hostname: namenode
    container_name: namenode
    volumes:
      - ./Makefile:/opt/hadoop/Makefile
      - /Users/ramindu/iit/lecture4/mapreduce-design-intro/resources:/opt/hadoop/resources
    ports:
      - 9870:9870
    env_file:
      - ./config
    environment:
      ENSURE_NAMENODE_DIR: "/tmp/hadoop-root/dfs/name"
      HDFS_SITE_XML_dfs.webhdfs.enabled: "true"
      CLUSTER_NAME: "test"
    command: ["hdfs", "namenode"]
    deploy:
      resources:
        limits:
          cpus: "1.5"  # limit to 1.5 CPU cores
          memory: "2g"  # limit memory to 2GB
  datanode_1:
    image: apache/hadoop:3
    platform: linux/amd64
    container_name: datanode
    command: [ "hdfs", "datanode" ]
    env_file:
      - ./config
    environment:
      - CLUSTER_NAME=test
  
  resourcemanager:
    image: apache/hadoop:3
    platform: linux/amd64
    hostname: resourcemanager
    container_name: resourcemanager
    command: [ "yarn", "resourcemanager" ]
    ports:
      - 8088:8088
    env_file:
      - ./config
    volumes:
      - ./test.sh:/opt/test.sh
    environment:
      - CLUSTER_NAME=test
    deploy:
      resources:
        limits:
          cpus: "1.5"  # limit to 1.5 CPU cores
          memory: "2g"  # limit memory to 2GB
  
  nodemanager:
    image: apache/hadoop:3
    platform: linux/amd64
    container_name: nodemanager
    command: [ "yarn", "nodemanager" ]
    env_file:
      - ./config
    environment:
      - CLUSTER_NAME=test
